{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ai', 'ali', 'haider', 'kashif'], dtype='<U6')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_list = ['haider','kashif','ali','ai','haider','ali']\n",
    "vocab = np.unique(sample_list)\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'and', 'boy', 'business', 'chess', 'dalla', 'good', 'haider',\n",
       "       'is', 'kashif', 'man', 'player', 'soban'], dtype='<U8')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = 'kashif is a good boy and a chess player'\n",
    "doc2 = \"haider is a business man\"\n",
    "doc3 = \"soban is a dalla\"\n",
    "\n",
    "super_list = []\n",
    "for doc in [doc1,doc2,doc3]:\n",
    "    for word in doc.split(' '):\n",
    "        super_list.append(word)\n",
    "vocab = np.unique(super_list)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kashif', 'is']\n",
      "['is', 'a']\n",
      "['a', 'good']\n",
      "['good', 'boy']\n",
      "['boy', 'and']\n",
      "['and', 'a']\n",
      "['a', 'chess']\n",
      "['chess', 'player']\n"
     ]
    }
   ],
   "source": [
    "for item in [doc1.split(\" \")[i:i+2] for i in range(len(doc1.split(\" \"))-1)]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['haider', 'is'], ['is', 'a'], ['a', 'business'], ['business', 'man']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc2.split(\" \")[i:i+2] for i in range(len(doc2.split(\" \"))-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_bi_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in [doc1, doc2, doc3]:\n",
    "    for item in [doc.split(\" \")[i:i+2] for i in range(len(doc.split(\" \"))-1)]:\n",
    "        super_bi_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kashif', 'is'],\n",
       " ['is', 'a'],\n",
       " ['a', 'good'],\n",
       " ['good', 'boy'],\n",
       " ['boy', 'and'],\n",
       " ['and', 'a'],\n",
       " ['a', 'chess'],\n",
       " ['chess', 'player'],\n",
       " ['haider', 'is'],\n",
       " ['is', 'a'],\n",
       " ['a', 'business'],\n",
       " ['business', 'man'],\n",
       " ['soban', 'is'],\n",
       " ['is', 'a'],\n",
       " ['a', 'dalla']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_bi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bi = np.unique(super_bi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bi = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kashif', 'is']\n",
      "['is', 'a']\n",
      "['a', 'good']\n",
      "['good', 'boy']\n",
      "['boy', 'and']\n",
      "['and', 'a']\n",
      "['a', 'chess']\n",
      "['chess', 'player']\n",
      "['haider', 'is']\n",
      "['is', 'a']\n",
      "['a', 'business']\n",
      "['business', 'man']\n",
      "['soban', 'is']\n",
      "['is', 'a']\n",
      "['a', 'dalla']\n"
     ]
    }
   ],
   "source": [
    "for item in super_bi_list:\n",
    "    print(item)\n",
    "    vocab_bi.add(tuple(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bi = list(vocab_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'dalla'),\n",
       " ('and', 'a'),\n",
       " ('business', 'man'),\n",
       " ('a', 'chess'),\n",
       " ('soban', 'is'),\n",
       " ('a', 'business'),\n",
       " ('is', 'a'),\n",
       " ('haider', 'is'),\n",
       " ('chess', 'player'),\n",
       " ('kashif', 'is'),\n",
       " ('a', 'good'),\n",
       " ('boy', 'and'),\n",
       " ('good', 'boy')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for item in vocab_bi:\n",
    "    text = item[0] + \" \" + item[1]\n",
    "    print(doc1.count(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.count(\"and a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'and',\n",
       " 'boy',\n",
       " 'business',\n",
       " 'chess',\n",
       " 'dalla',\n",
       " 'good',\n",
       " 'haider',\n",
       " 'is',\n",
       " 'kashif',\n",
       " 'man',\n",
       " 'player',\n",
       " 'soban']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_mat = np.zeros((3, len(columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.split(\" \").count(\"kashif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate([doc1,doc2,doc3]):\n",
    "    for j in range(len(columns)):\n",
    "        unigram_mat[i][j] = doc.split(\" \").count(columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 'a', 'b', 'c']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,2,3,4]\n",
    "l2 = ['a','b','c']\n",
    "\n",
    "l1+l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for i in l1+l2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a\n",
      "2 b\n",
      "3 c\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(l1,l2):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
